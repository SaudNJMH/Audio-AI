{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e659328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "Number of GPUs: 1\n",
      "Current GPU: 0\n",
      "GPU name: NVIDIA GeForce RTX 2060\n",
      "ROOT: C:\\Users\\AboMajed\\audio-seg\\Audio-AI\n",
      "AUDIO_DIR exists: True\n",
      "DATASET_CSV exists: True\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current GPU: {torch.cuda.current_device()}\")\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "ROOT = Path.cwd().resolve().parents[0] if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "AUDIO_DIR = ROOT / \"audios-wav\"\n",
    "DATASET_CSV = ROOT / \"data\" / \"cleaned_dataset.csv\"\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"AUDIO_DIR exists:\", AUDIO_DIR.exists())\n",
    "print(\"DATASET_CSV exists:\", DATASET_CSV.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59e58989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>speaker_count</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../audios-wav/audios-ar/3_speakers_ar/three_sp...</td>\n",
       "      <td>3 Speakers</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../audios-wav/audios-en/2_speakers_en/two_spea...</td>\n",
       "      <td>2 Speakers</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../audios-wav/audios-ar/2_speakers_ar/two_spea...</td>\n",
       "      <td>2 Speakers</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../audios-wav/audios-ar/3_speakers_ar/three_sp...</td>\n",
       "      <td>3 Speakers</td>\n",
       "      <td>ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../audios-wav/audios-en/2_speakers_en/two_spea...</td>\n",
       "      <td>2 Speakers</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio speaker_count language\n",
       "0  ../audios-wav/audios-ar/3_speakers_ar/three_sp...    3 Speakers       ar\n",
       "1  ../audios-wav/audios-en/2_speakers_en/two_spea...    2 Speakers       en\n",
       "2  ../audios-wav/audios-ar/2_speakers_ar/two_spea...    2 Speakers       ar\n",
       "3  ../audios-wav/audios-ar/3_speakers_ar/three_sp...    3 Speakers       ar\n",
       "4  ../audios-wav/audios-en/2_speakers_en/two_spea...    2 Speakers       en"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_CSV)\n",
    "print(\"Total rows:\", len(df))\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a9110b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: three_speakers7_ar.wav | language=ar | true=3 Speakers\n",
      "✓ Pipeline moved to GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AboMajed\\audio-seg\\Audio-AI\\.venv\\lib\\site-packages\\pyannote\\audio\\utils\\reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
      "It can be re-enabled by calling\n",
      "   >>> import torch\n",
      "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
      "   >>> torch.backends.cudnn.allow_tf32 = True\n",
      "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\AboMajed\\audio-seg\\Audio-AI\\.venv\\lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted speaker count: 3\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from pyannote.audio import Pipeline as PNA_Pipeline\n",
    "\n",
    "row = df.iloc[0]\n",
    "audio_path = Path(row[\"audio\"]).resolve()\n",
    "print(f\"Testing: {audio_path.name} | language={row['language']} | true={row['speaker_count']}\")\n",
    "\n",
    "token = os.environ.get(\"HUGGINGFACE_TOKEN\")\n",
    "pipe = PNA_Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=token\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    pipe = pipe.to(torch.device(\"cuda\"))\n",
    "    print(\"✓ Pipeline moved to GPU\")\n",
    "else:\n",
    "    print(\"⚠ Pipeline using CPU\")\n",
    "diarization = pipe(str(audio_path))\n",
    "\n",
    "speakers = {spk for _, _, spk in diarization.itertracks(yield_label=True)}\n",
    "print(\"Predicted speaker count:\", len(speakers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f01c62ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyAnnote pipeline ready: <class 'pyannote.audio.pipelines.speaker_diarization.SpeakerDiarization'>\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "from pyannote.audio import Pipeline as PNA_Pipeline\n",
    "\n",
    "# (Re)create the global pipeline only if missing\n",
    "if 'pipe' not in globals() or pipe is None:\n",
    "    token = os.environ.get(\"HUGGINGFACE_TOKEN\")\n",
    "    if not token:\n",
    "        raise RuntimeError(\"HUGGINGFACE_TOKEN not found. Put it in .env and rerun load_dotenv().\")\n",
    "    pipe = PNA_Pipeline.from_pretrained(\n",
    "        \"pyannote/speaker-diarization-3.1\",\n",
    "        use_auth_token=token\n",
    "    )\n",
    "print(\"PyAnnote pipeline ready:\", type(pipe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "949f015e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\Users\\AboMajed\\audio-seg\\Audio-AI\\results\\pyannote_predictions.csv\n",
      "Total rows: 60 | Failures: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>language</th>\n",
       "      <th>true_speakers</th>\n",
       "      <th>pred_speakers</th>\n",
       "      <th>runtime_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...</td>\n",
       "      <td>ar</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>16.593641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13.713065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...</td>\n",
       "      <td>ar</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9.936236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...</td>\n",
       "      <td>ar</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11.928650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>13.806100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.702929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15.398440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...</td>\n",
       "      <td>en</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.845201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>17.384885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9.708357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio language  true_speakers  \\\n",
       "0  C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...       ar              3   \n",
       "1  C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...       en              2   \n",
       "2  C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...       ar              2   \n",
       "3  C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...       ar              3   \n",
       "4  C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...       en              2   \n",
       "5  C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...       en              1   \n",
       "6  C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...       en              2   \n",
       "7  C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...       en              1   \n",
       "8  C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...       en              2   \n",
       "9  C:\\Users\\AboMajed\\audio-seg\\Audio-AI\\audios-wa...       en              2   \n",
       "\n",
       "   pred_speakers  runtime_sec  \n",
       "0              3    16.593641  \n",
       "1              2    13.713065  \n",
       "2              2     9.936236  \n",
       "3              3    11.928650  \n",
       "4              3    13.806100  \n",
       "5              1     8.702929  \n",
       "6              2    15.398440  \n",
       "7              1     9.845201  \n",
       "8              2    17.384885  \n",
       "9              2     9.708357  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import time, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ensure results dir exists\n",
    "RESULTS_DIR = Path.cwd().parents[0] / \"results\" if Path.cwd().name == \"notebooks\" else Path.cwd() / \"results\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_CSV = RESULTS_DIR / \"pyannote_predictions.csv\"\n",
    "\n",
    "# reuse the already-loaded pipeline `pipe`\n",
    "assert 'pipe' in globals(), \"Run the PyAnnote smoke-test cell first to create `pipe`.\"\n",
    "\n",
    "def true_count(s):\n",
    "    # extract the first integer from \"speaker_count\" (e.g., '3 Speakers' -> 3)\n",
    "    m = re.search(r\"\\d+\", str(s))\n",
    "    return int(m.group()) if m else np.nan\n",
    "\n",
    "rows = []\n",
    "failures = 0\n",
    "\n",
    "for i, r in df.iterrows():\n",
    "    audio_path = Path(r[\"audio\"]).resolve()\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        dia = pipe(str(audio_path))\n",
    "        speakers = {spk for _, _, spk in dia.itertracks(yield_label=True)}\n",
    "        pred = len(speakers)\n",
    "    except Exception as e:\n",
    "        pred = np.nan\n",
    "        failures += 1\n",
    "    dt = time.time() - t0\n",
    "\n",
    "    rows.append({\n",
    "        \"audio\": str(audio_path),\n",
    "        \"language\": r[\"language\"],               # untouched\n",
    "        \"true_speakers\": true_count(r[\"speaker_count\"]),\n",
    "        \"pred_speakers\": pred,\n",
    "        \"runtime_sec\": dt,\n",
    "    })\n",
    "\n",
    "pred_df = pd.DataFrame(rows)\n",
    "pred_df.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(f\"Saved: {OUT_CSV}\")\n",
    "print(f\"Total rows: {len(pred_df)} | Failures: {failures}\")\n",
    "display(pred_df.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
