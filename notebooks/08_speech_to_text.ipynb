{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "\n",
    "AUDIO_DIR = '../audios-wav/12-audios-ar-en'\n",
    "DIARIZATION_OUTPUT_DIR = '../results/Task 2 Results'\n",
    "GROUND_TRUTH_TRANSCRIPTS_DIR = '../data'\n",
    "OUTPUT_TRANSCRIPTS_DIR = '../Task 3 Results'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986bc469",
   "metadata": {},
   "source": [
    "# Hasan Run This only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75b9c72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FasterWhisper model: large-v2 with compute type: int8 for CPU...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Voice-AI/Audio-AI/.venv/lib/python3.9/site-packages/tqdm/contrib/concurrent.py:51\u001b[0m, in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m PoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers, initializer\u001b[38;5;241m=\u001b[39mtqdm_class\u001b[38;5;241m.\u001b[39mset_lock,\n\u001b[1;32m     50\u001b[0m                   initargs\u001b[38;5;241m=\u001b[39m(lk,)) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Voice-AI/Audio-AI/.venv/lib/python3.9/site-packages/tqdm/std.py:1169\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable:\n\u001b[0;32m-> 1169\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.23/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:609\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.23/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.23/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading FasterWhisper model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with compute type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompute_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for CPU...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mWhisperModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFasterWhisper model loaded successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Voice-AI/Audio-AI/.venv/lib/python3.9/site-packages/faster_whisper/transcribe.py:655\u001b[0m, in \u001b[0;36mWhisperModel.__init__\u001b[0;34m(self, model_size_or_path, device, device_index, compute_type, cpu_threads, num_workers, download_root, local_files_only, files, revision, use_auth_token, **model_kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m model_size_or_path\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 655\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_size_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m ctranslate2\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mWhisper(\n\u001b[1;32m    664\u001b[0m     model_path,\n\u001b[1;32m    665\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m    672\u001b[0m )\n\u001b[1;32m    674\u001b[0m tokenizer_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Voice-AI/Audio-AI/.venv/lib/python3.9/site-packages/faster_whisper/utils.py:118\u001b[0m, in \u001b[0;36mdownload_model\u001b[0;34m(size_or_id, output_dir, local_files_only, cache_dir, revision, use_auth_token)\u001b[0m\n\u001b[1;32m    115\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhuggingface_hub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    120\u001b[0m     huggingface_hub\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mHfHubHTTPError,\n\u001b[1;32m    121\u001b[0m     requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mConnectionError,\n\u001b[1;32m    122\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    123\u001b[0m     logger \u001b[38;5;241m=\u001b[39m get_logger()\n",
      "File \u001b[0;32m~/Voice-AI/Audio-AI/.venv/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Voice-AI/Audio-AI/.venv/lib/python3.9/site-packages/huggingface_hub/_snapshot_download.py:327\u001b[0m, in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001b[0m\n\u001b[1;32m    325\u001b[0m         _inner_hf_hub_download(file)\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     \u001b[43mthread_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_inner_hf_hub_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiltered_repo_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_desc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# User can use its own tqdm class or the default one from `huggingface_hub.utils`\u001b[39;49;00m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtqdm_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhf_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(local_dir))\n",
      "File \u001b[0;32m~/Voice-AI/Audio-AI/.venv/lib/python3.9/site-packages/tqdm/contrib/concurrent.py:69\u001b[0m, in \u001b[0;36mthread_map\u001b[0;34m(fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mEquivalent of `list(map(fn, *iterables))`\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    [default: max(32, cpu_count() + 4)].\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfutures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_executor_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Voice-AI/Audio-AI/.venv/lib/python3.9/site-packages/tqdm/contrib/concurrent.py:51\u001b[0m, in \u001b[0;36m_executor_map\u001b[0;34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name\u001b[38;5;241m=\u001b[39mlock_name) \u001b[38;5;28;01mas\u001b[39;00m lk:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m PoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mmax_workers, initializer\u001b[38;5;241m=\u001b[39mtqdm_class\u001b[38;5;241m.\u001b[39mset_lock,\n\u001b[1;32m     50\u001b[0m                       initargs\u001b[38;5;241m=\u001b[39m(lk,)) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m---> 51\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(tqdm_class(ex\u001b[38;5;241m.\u001b[39mmap(fn, \u001b[38;5;241m*\u001b[39miterables, chunksize\u001b[38;5;241m=\u001b[39mchunksize), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.23/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:637\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.23/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.23/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py:1060\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1060\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.23/Frameworks/Python.framework/Versions/3.9/lib/python3.9/threading.py:1080\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1080\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1081\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_size = \"large-v2\" \n",
    "compute_type = \"int8\" \n",
    "\n",
    "print(f\"Loading FasterWhisper model: {model_size} with compute type: {compute_type} for CPU...\")\n",
    "try:\n",
    "    model = WhisperModel(model_size, device=\"cpu\", compute_type=compute_type)\n",
    "    print(\"FasterWhisper model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading FasterWhisper model: {e}\")\n",
    "    print(\"If you encounter 'out of memory' errors with 'large-v2', try 'medium' or 'small'.\")\n",
    "    print(\"Please ensure you have enough disk space and a stable internet connection if downloading the model weights.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1401bb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved AUDIO_DIR: /Users/s.n.h/Voice-AI/Audio-AI/audios-wav/12-audios-ar-en\n",
      "Resolved DIARIZATION_OUTPUT_DIR: /Users/s.n.h/Voice-AI/Audio-AI/results/Task 2 Results\n",
      "Found 12 audio files:\n",
      "- 6-audios-ar/1_speaker_ar/solo10_ar.wav\n",
      "- 6-audios-ar/1_speaker_ar/solo3_ar.wav\n",
      "- 6-audios-ar/2_speakers_ar/two_speakers10_ar.wav\n",
      "- 6-audios-ar/2_speakers_ar/two_speakers7_ar.wav\n",
      "- 6-audios-ar/3_speakers_ar/three_speakers1_ar.wav\n",
      "- 6-audios-ar/3_speakers_ar/three_speakers5_ar.wav\n",
      "- 6-audios-en/1_speaker_en/solo2_en.wav\n",
      "- 6-audios-en/1_speaker_en/solo3_en.wav\n",
      "- 6-audios-en/2_speakers_en/two_speakers7_en.wav\n",
      "- 6-audios-en/2_speakers_en/two_speakers8_en.wav\n",
      "- 6-audios-en/3_speakers_en/three_speakers2_en.wav\n",
      "- 6-audios-en/3_speakers_en/three_speakers8_en.wav\n",
      "\n",
      "Attempting to load central diarization summary from 'pyannote_summary.csv'...\n",
      "Diarization summary 'pyannote_summary.csv' loaded successfully!\n",
      "                                               audio  n_segments  runtime_sec  \\\n",
      "0  ../audios-wav/12-audios-ar-en/6-audios-ar/1_sp...           7   242.921457   \n",
      "1  ../audios-wav/12-audios-ar-en/6-audios-ar/1_sp...          62   219.935136   \n",
      "2  ../audios-wav/12-audios-ar-en/6-audios-ar/2_sp...          37   215.254184   \n",
      "3  ../audios-wav/12-audios-ar-en/6-audios-ar/2_sp...          80   282.313628   \n",
      "4  ../audios-wav/12-audios-ar-en/6-audios-ar/3_sp...         107   362.471811   \n",
      "\n",
      "                                         output_file  \n",
      "0  ../results/Task 2 Results/pyannote_predictions...  \n",
      "1  ../results/Task 2 Results/pyannote_predictions...  \n",
      "2  ../results/Task 2 Results/pyannote_predictions...  \n",
      "3  ../results/Task 2 Results/pyannote_predictions...  \n",
      "4  ../results/Task 2 Results/pyannote_predictions...  \n",
      "Resolved sample JSON path: ../results/Task 2 Results/pyannote_predictions/solo10_ar_pyannote.json\n",
      "\n",
      "Successfully located a sample JSON file: ../results/Task 2 Results/pyannote_predictions/solo10_ar_pyannote.json\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "\n",
    "# Print resolved paths for debugging\n",
    "print(f\"Resolved AUDIO_DIR: {os.path.abspath(AUDIO_DIR)}\")\n",
    "print(f\"Resolved DIARIZATION_OUTPUT_DIR: {os.path.abspath(DIARIZATION_OUTPUT_DIR)}\")\n",
    "\n",
    "# List all audio files in both subfolders of 12-audios-ar-en (recursively)\n",
    "subfolders = ['6-audios-ar', '6-audios-en']\n",
    "audio_files = []\n",
    "for sub in subfolders:\n",
    "    sub_path = os.path.join(AUDIO_DIR, sub)\n",
    "    found = glob.glob(os.path.join(sub_path, '**', '*.wav'), recursive=True)\n",
    "    audio_files.extend(found)\n",
    "\n",
    "audio_files = sorted(audio_files)\n",
    "\n",
    "if not audio_files:\n",
    "    print(f\"No WAV audio files found in subfolders of '{AUDIO_DIR}' (recursive search). Please check the path and file extensions.\")\n",
    "else:\n",
    "    print(f\"Found {len(audio_files)} audio files:\")\n",
    "    for af in audio_files:\n",
    "        print(f\"- {os.path.relpath(af, AUDIO_DIR)}\")\n",
    "\n",
    "print(\"\\nAttempting to load central diarization summary from 'pyannote_summary.csv'...\")\n",
    "\n",
    "summary_csv_path = os.path.join(DIARIZATION_OUTPUT_DIR, 'pyannote_summary.csv')\n",
    "\n",
    "if os.path.exists(summary_csv_path):\n",
    "    diarization_summary_df = pd.read_csv(summary_csv_path)\n",
    "    print(\"Diarization summary 'pyannote_summary.csv' loaded successfully!\")\n",
    "    print(diarization_summary_df.head())\n",
    "\n",
    "    if 'output_file' in diarization_summary_df.columns and not diarization_summary_df.empty:\n",
    "        sample_json_path = diarization_summary_df['output_file'].iloc[0]\n",
    "        # If path is already relative to project root, use as-is\n",
    "        if sample_json_path.startswith(\"../results/\"):\n",
    "            full_sample_json_path = os.path.normpath(sample_json_path)\n",
    "        else:\n",
    "            full_sample_json_path = os.path.normpath(os.path.join(DIARIZATION_OUTPUT_DIR, sample_json_path))\n",
    "        print(f\"Resolved sample JSON path: {full_sample_json_path}\")\n",
    "\n",
    "        if os.path.exists(full_sample_json_path):\n",
    "            print(f\"\\nSuccessfully located a sample JSON file: {full_sample_json_path}\")\n",
    "        else:\n",
    "            print(f\"\\nWARNING: Could not find sample JSON file at '{full_sample_json_path}'.\")\n",
    "            print(\"Please ensure 'output_file' paths in pyannote_summary.csv are correct relative to the project root or DIARIZATION_OUTPUT_DIR.\")\n",
    "    else:\n",
    "        print(\"\\nWARNING: 'output_file' column not found or summary CSV is empty.\")\n",
    "\n",
    "else:\n",
    "    print(f\"ERROR: 'pyannote_summary.csv' not found at '{summary_csv_path}'.\")\n",
    "    print(\"Please ensure your Task 2 output structure matches this expectation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64f743ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensured output directory for transcripts exists: /Users/s.n.h/Voice-AI/Audio-AI/Task 3 Results\n",
      "\n",
      "Processing audio file: solo10_ar.wav\n",
      "Error transcribing 'solo10_ar.wav': name 'model' is not defined\n",
      "\n",
      "Processing audio file: solo3_ar.wav\n",
      "Error transcribing 'solo3_ar.wav': name 'model' is not defined\n",
      "\n",
      "Processing audio file: two_speakers10_ar.wav\n",
      "Error transcribing 'two_speakers10_ar.wav': name 'model' is not defined\n",
      "\n",
      "Processing audio file: two_speakers7_ar.wav\n",
      "Error transcribing 'two_speakers7_ar.wav': name 'model' is not defined\n",
      "\n",
      "Processing audio file: three_speakers1_ar.wav\n",
      "Error transcribing 'three_speakers1_ar.wav': name 'model' is not defined\n",
      "\n",
      "Processing audio file: three_speakers5_ar.wav\n",
      "Error transcribing 'three_speakers5_ar.wav': name 'model' is not defined\n",
      "\n",
      "Processing audio file: solo2_en.wav\n",
      "Error transcribing 'solo2_en.wav': name 'model' is not defined\n",
      "\n",
      "Processing audio file: solo3_en.wav\n",
      "Error transcribing 'solo3_en.wav': name 'model' is not defined\n",
      "\n",
      "Processing audio file: two_speakers7_en.wav\n",
      "Error transcribing 'two_speakers7_en.wav': name 'model' is not defined\n",
      "\n",
      "Processing audio file: two_speakers8_en.wav\n",
      "Error transcribing 'two_speakers8_en.wav': name 'model' is not defined\n",
      "\n",
      "Processing audio file: three_speakers2_en.wav\n",
      "Error transcribing 'three_speakers2_en.wav': name 'model' is not defined\n",
      "\n",
      "Processing audio file: three_speakers8_en.wav\n",
      "Error transcribing 'three_speakers8_en.wav': name 'model' is not defined\n",
      "\n",
      "Transcription process complete for all found audio files.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(OUTPUT_TRANSCRIPTS_DIR, exist_ok=True)\n",
    "print(f\"Ensured output directory for transcripts exists: {os.path.abspath(OUTPUT_TRANSCRIPTS_DIR)}\")\n",
    "\n",
    "# Iterate through each audio file found\n",
    "for audio_path in audio_files:\n",
    "    audio_filename = os.path.basename(audio_path)\n",
    "    print(f\"\\nProcessing audio file: {audio_filename}\")\n",
    "\n",
    "    # Define output path for the transcript\n",
    "    transcript_output_path = os.path.join(OUTPUT_TRANSCRIPTS_DIR, f\"{os.path.splitext(audio_filename)[0]}.txt\")\n",
    "\n",
    "    try:\n",
    "        # Transcribe the audio file\n",
    "        segments, info = model.transcribe(audio_path, beam_size=5)\n",
    "\n",
    "        # Prepare text for saving\n",
    "        full_transcript = []\n",
    "        for segment in segments:\n",
    "            full_transcript.append(segment.text)\n",
    "\n",
    "        # Join segments and save to a text file\n",
    "        with open(transcript_output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(\"\\n\".join(full_transcript))\n",
    "\n",
    "        print(f\"Transcription for '{audio_filename}' completed and saved to: {transcript_output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error transcribing '{audio_filename}': {e}\")\n",
    "\n",
    "print(\"\\nTranscription process complete for all found audio files.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (audio-ai)",
   "language": "python",
   "name": "audio-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
